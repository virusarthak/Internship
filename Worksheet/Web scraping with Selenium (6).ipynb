{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping with Selenium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important library\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you want to search : Data Analyst\n",
      "Enter the location :- Bangalore\n",
      "exp_required 20\n",
      "company_name 20\n",
      "job_location 20\n",
      "title 20\n"
     ]
    }
   ],
   "source": [
    "# automating the chrome browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\") # opening th site\n",
    "\n",
    "# automatic the search \n",
    "user_input = input(\"what do you want to search : \")\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.clear() # ensuring the search bar is clear \n",
    "search_job.send_keys(user_input) # sending input to search bar\n",
    "time.sleep(4) # after search code will stop for 4 sec\n",
    "\n",
    "\n",
    "# Automatic job_loc \n",
    "\n",
    "enter_loc = input(\"Enter the location :- \")\n",
    "job_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "job_loc.clear() # ensuring the search bar is clear \n",
    "job_loc.send_keys(enter_loc)\n",
    "time.sleep(4) # after search code will stop for 4 sec\n",
    "\n",
    "# automating submit button\n",
    "\n",
    "submit_but = driver.find_element_by_xpath(\"//button[@class = 'btn']\")\n",
    "submit_but.click()\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# Extracting the job_title\n",
    "job_title = driver.find_elements_by_xpath(\"//a [@class ='title fw500 ellipsis']\")\n",
    "title = [title.text for title in job_title]\n",
    "time.sleep(4)\n",
    "\n",
    "# extracting job location\n",
    "location = driver.find_elements_by_xpath(\"// li [@class = 'fleft grey-text br2 placeHolderLi location']/span\")\n",
    "\n",
    "job_location = [loc.text for loc in location]\n",
    "time.sleep(4)\n",
    "\n",
    "# extracting company name\n",
    "\n",
    "company = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "company_name = [name.text for name in company]\n",
    "time.sleep(4)\n",
    "# Extracting experiance \n",
    "\n",
    "experiance = driver.find_elements_by_xpath(\"// li[@class = 'fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "\n",
    "exp_required = [exp.text for exp in experiance]\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# printing len of the data \n",
    "print(\"exp_required\",len(exp_required))\n",
    "print(\"company_name\",len(company_name))\n",
    "print(\"job_location\",len(job_location))\n",
    "print(\"title\",len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Hiring Data Analysts For E commerce Platform |...   \n",
       "2                                       Data Analyst   \n",
       "3  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "4  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "\n",
       "                                       company_name exp_required  \n",
       "0                Inflexion Analytix Private Limited      0-3 Yrs  \n",
       "1                  Allegis Services India Pvt. Ltd.      0-5 Yrs  \n",
       "2                                 Applied Materials     7-10 Yrs  \n",
       "3  PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd      2-4 Yrs  \n",
       "4                    Tata Consultancy Services Ltd.      4-9 Yrs  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analytic_jobs = pd.DataFrame({\"title\":title[0:10],\"job_location\":job_location[0:10],\"company_name\":company_name[0:10],\"exp_required\":exp_required[0:10]})\n",
    "data_analytic_jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to search Data scientist / machine learning \n",
      "Please mention the location  Bangalore/ Bangluru\n",
      "title 20\n",
      "location 20\n",
      "company_name 20\n",
      "description 20\n"
     ]
    }
   ],
   "source": [
    "# automating the chrome browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening site\n",
    "driver.get(\"https://www.naukri.com/\") # opening th site\n",
    "\n",
    "# Automating search bar\n",
    "user_input = input(\"What do you want to search \")\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.clear()\n",
    "search_job.send_keys(user_input)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# Automating search bar_location\n",
    "locaton_input = input(\"Please mention the location  \")\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.clear()\n",
    "search_loc.send_keys(locaton_input)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# automating submit button \n",
    "\n",
    "submit  = driver.find_element_by_xpath(\"//button[@class = 'btn']\")\n",
    "submit.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# extracting job tile\n",
    "# job_title = driver.find_elements_by_xpath(\"//a [@class ='title fw500 ellipsis']\")\n",
    "# title = [title.text for title in job_title]\n",
    "# time.sleep(3)\n",
    "\n",
    "# extracting job location\n",
    "# location = driver.find_elements_by_xpath(\"// li [@class = 'fleft grey-text br2 placeHolderLi location']/span\")\n",
    "\n",
    "# job_location = [loc.text for loc in location]\n",
    "# time.sleep(3)\n",
    "\n",
    "# extracting company name\n",
    "\n",
    "# company = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "# company_name = [name.text for name in company]\n",
    "# time.sleep(3)\n",
    "\n",
    "\n",
    "# extracting full job description \n",
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "urls = [url.get_attribute(\"href\") for url in job_title ]\n",
    "\n",
    "description = []\n",
    "title = []\n",
    "location =[]\n",
    "company_name =[]\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # title\n",
    "    try:\n",
    "        for j in driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\"):\n",
    "            title.append(j.text)\n",
    "            time.sleep(2)\n",
    "            \n",
    "    except:\n",
    "        title.append(\"__\")\n",
    "\n",
    "    \n",
    "    # location  \n",
    "    try:\n",
    "        for k in driver.find_elements_by_xpath(\"//span[@class='location ']/a\"):\n",
    "            location.append(k.text)\n",
    "            time.sleep(2)\n",
    "            \n",
    "    except:\n",
    "        location.append(\"__\")\n",
    "        \n",
    "        \n",
    "#      Company name\n",
    "    try:\n",
    "        for l in driver.find_elements_by_xpath(\"//div[@class='jd-header-comp-name']/a[1]\"):\n",
    "            company_name.append(l.text)\n",
    "            time.sleep(2)\n",
    "            \n",
    "    except:\n",
    "        company_name.append(\"__\")\n",
    "\n",
    "        \n",
    "    # description\n",
    "    \n",
    "    try:\n",
    "        for m in driver.find_elements_by_xpath(\"//section[@class='job-desc']\"):\n",
    "            description.append(m.text)\n",
    "            time.sleep(2)\n",
    "    except:\n",
    "        description.append(\"__\")\n",
    "    \n",
    "\n",
    "\n",
    "# find the lenth of all variable \n",
    "\n",
    "print(\"title\",len(title))\n",
    "print(\"location\",len(location))\n",
    "print(\"company_name\",len(company_name[::2]))\n",
    "print(\"description\",len(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = company_name[::2] # company colunm has comma as well thus  extracting only company name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>com_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Data Scientist - Machine Learning/ Python</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Job description\\nWhat you would do as a Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist / Machine Learning / AI ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bion</td>\n",
       "      <td>Job description\\nLooking for a seasoned Progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist / Machine Learning / AI ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bion</td>\n",
       "      <td>Job description\\nLooking for a seasoned Progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chief Data Scientist - Machine Learning/ Python</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Job description\\nChief Data Scientist - Machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chief Data Scientist - Machine Learning/python</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Job description\\n- Work on the data science ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Scientist/nlp/machine Learning/data Mining</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Career Maker</td>\n",
       "      <td>Job description\\nSenior Scientist/NLP/Machine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Scientist/nlp/ Machine Learning/data Mi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Career Maker</td>\n",
       "      <td>Job description\\nMajor responsibilities:\\n\\n- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Scientist/nlp/ Machine Learning/ Data M...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Career Maker</td>\n",
       "      <td>Job description\\nMajor responsibilities:\\n\\n- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Scientist/nlp/machine Learning/data Min...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Career Maker</td>\n",
       "      <td>Job description\\nMajor responsibilities:\\n\\n- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title             location  \\\n",
       "0    Chief Data Scientist - Machine Learning/ Python  Bangalore/Bengaluru   \n",
       "1  Senior Data Scientist / Machine Learning / AI ...  Bangalore/Bengaluru   \n",
       "2  Senior Data Scientist / Machine Learning / AI ...  Bangalore/Bengaluru   \n",
       "3                  Data Scientist - Machine Learning  Bangalore/Bengaluru   \n",
       "4    Chief Data Scientist - Machine Learning/ Python  Bangalore/Bengaluru   \n",
       "5     Chief Data Scientist - Machine Learning/python  Bangalore/Bengaluru   \n",
       "6  Senior Scientist/nlp/machine Learning/data Mining  Bangalore/Bengaluru   \n",
       "7  Senior Scientist/nlp/ Machine Learning/data Mi...  Bangalore/Bengaluru   \n",
       "8  Senior Scientist/nlp/ Machine Learning/ Data M...  Bangalore/Bengaluru   \n",
       "9  Senior Scientist/nlp/machine Learning/data Min...  Bangalore/Bengaluru   \n",
       "\n",
       "       com_name                                        description  \n",
       "0      Catalyst  Job description\\nWhat you would do as a Data S...  \n",
       "1          Bion  Job description\\nLooking for a seasoned Progra...  \n",
       "2          Bion  Job description\\nLooking for a seasoned Progra...  \n",
       "3      Catalyst  Job description\\nRoles and Responsibilities\\n-...  \n",
       "4      Catalyst  Job description\\nChief Data Scientist - Machin...  \n",
       "5      Catalyst  Job description\\n- Work on the data science ro...  \n",
       "6  Career Maker  Job description\\nSenior Scientist/NLP/Machine ...  \n",
       "7  Career Maker  Job description\\nMajor responsibilities:\\n\\n- ...  \n",
       "8  Career Maker  Job description\\nMajor responsibilities:\\n\\n- ...  \n",
       "9  Career Maker  Job description\\nMajor responsibilities:\\n\\n- ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sci_df = pd.DataFrame({\"title\":title[:10],\"location\":location[:10],\"com_name\":com_name[:10],\"description\":description[:10]})\n",
    "data_sci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job name :- Data scientist\n"
     ]
    }
   ],
   "source": [
    "# initiazing  crome browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Defining URls\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "\n",
    "# openin URL\n",
    "\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# automating search bar and find desire job\n",
    "user_input = input(\"Enter the job name :- \")\n",
    "search_bar = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys(user_input)\n",
    "\n",
    "# Automating submit button\n",
    "submit_button = driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "submit_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# auotmating location filter\n",
    "\n",
    "loc_check_box = driver.find_elements_by_xpath(\"//p [@class= 'grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "for i in loc_check_box:\n",
    "    if i.text == \"Delhi / NCR\":\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "salary_check_box = driver.find_elements_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "for j in salary_check_box:\n",
    "    if j.text == \"3-6 Lakhs\":\n",
    "        j.click()\n",
    "        break\n",
    "\n",
    "# extracting title\n",
    "try:\n",
    "    title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    job_title = [job.text for job in title]\n",
    "except:\n",
    "    job_title.append(\"__\")\n",
    "        \n",
    "\n",
    "# extracting location\n",
    "\n",
    "try:\n",
    "    location = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    job_location = [loc.text for loc in location]\n",
    "except:\n",
    "    job_location.append(\"__\")\n",
    "\n",
    "\n",
    "# extracting company name\n",
    "\n",
    "try:\n",
    "    company = driver.find_elements_by_xpath(\"//a[@class ='subTitle ellipsis fleft']\")\n",
    "    company_name = [loc.text for loc in location]\n",
    "except:\n",
    "    company_name.append(\"__\")\n",
    "\n",
    "# extracting exp\n",
    "\n",
    "try:\n",
    "    exp = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "    job_exp = [loc.text for loc in exp]\n",
    "except:\n",
    "    job_exp.append(\"__\")\n",
    "\n",
    "\n",
    "print(len(job_title))\n",
    "print(len(location))\n",
    "print(len(company_name))\n",
    "print(len(job_exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Ally -eXecutive HR Consulting Partner</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TALCHEMY SOLUTIONS LLP</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Platlap Solutions</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Vahak</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data Scientist - High growth VC backed Influen...   \n",
       "2           Excellent opportunity For Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3           New Delhi, Gurgaon/Gurugram, Delhi / NCR   \n",
       "4                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "\n",
       "                            company_name  job_exp  \n",
       "0  Ally -eXecutive HR Consulting Partner  0-3 Yrs  \n",
       "1                 TALCHEMY SOLUTIONS LLP  3-5 Yrs  \n",
       "2                           Confidential  3-7 Yrs  \n",
       "3                      Platlap Solutions  3-5 Yrs  \n",
       "4                                  Vahak  3-6 Yrs  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filer_data_scientist_jobs = pd.DataFrame({\"job_title\":job_title[0:10],\"job_location\":job_location[0:10],\"company_name\":company_name[0:10],\"job_exp\":job_exp[0:10]})\n",
    "filer_data_scientist_jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_name 30\n",
      "job_post_days 30\n",
      "company_rating 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_post_days</th>\n",
       "      <th>company_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apsidata Solutions</td>\n",
       "      <td>4d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>1d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company_name job_post_days company_rating\n",
       "0            Apsidata Solutions            4d            NaN\n",
       "1                Biz2Credit Inc          30d+            3.8\n",
       "2  Salasar New Age Technologies          30d+            NaN\n",
       "3                         Adobe            6d            4.4\n",
       "4                      Techlive          30d+            5.0\n",
       "5                 NatWest Group            1d            3.9\n",
       "6        Data Trained Education            1d            NaN\n",
       "7                     dunnhumby           24h            4.1\n",
       "8                       CRMNEXT           12d            3.6\n",
       "9                      Ericsson           13d            4.1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiazing  crome browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Defining URls\n",
    "url = \"https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm\"\n",
    "\n",
    "# openin URL\n",
    "driver.get(url)\n",
    "driver.maximize_window() # maximizing the window\n",
    "\n",
    "# get company_name\n",
    "\n",
    "\n",
    "company = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']\")\n",
    "company_name = [name.text for name in company]\n",
    "\n",
    "#no of days ago job was posted \n",
    "\n",
    "days = driver.find_elements_by_xpath(\"//div[@class ='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "job_post_days = [day.text for day in days]\n",
    "\n",
    "\n",
    "# company Ratings\n",
    "rating  = driver.find_elements_by_xpath(\"//div[@class ='d-flex flex-column css-x75kgh e1rrn5ka3']\")\n",
    "company_rating = [rank.text for rank in rating]\n",
    "\n",
    "\n",
    "# checking the length \n",
    "print(\"company_name\",len(company_name))\n",
    "print(\"job_post_days\",len(job_post_days))\n",
    "print(\"company_rating\",len(company_rating))\n",
    "\n",
    "# creating Data frame\n",
    "df = pd.DataFrame({\"company_name\":company_name[:10],\"job_post_days\":job_post_days[:10],\"company_rating\":company_rating[:10]})\n",
    "df.replace(\"\",np.nan, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job title:- Data scientist\n",
      "Enter the job location:- Noida\n",
      "Company_name 20\n",
      "number_of_salary 20\n",
      "Average_salary 20\n",
      "Min_salary 20\n",
      "Max_Salary 20\n"
     ]
    }
   ],
   "source": [
    "# automating browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url) # opening web page\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "# search Designation \n",
    "\n",
    "desigination = input(\"Enter the job title:- \")\n",
    "Location  = input(\"Enter the job location:- \")\n",
    "\n",
    "search_job = driver.find_element_by_id(\"KeywordSearch\")\n",
    "search_job.clear()\n",
    "search_job.send_keys(desigination)\n",
    "time.sleep(3)\n",
    "\n",
    "# entering location \n",
    "search_loc = driver.find_element_by_id(\"LocationSearch\")\n",
    "search_loc.clear()\n",
    "search_loc.send_keys(Location)\n",
    "time.sleep(3)\n",
    "\n",
    "# click on search button \n",
    "driver.find_element_by_id(\"HeroSearchButton\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "# extracting all the information \n",
    "\n",
    "required_details = driver.find_elements_by_xpath(\"//div[@class='row no-gutters mx-0 py align-items-center css-1u4lhyp']\")\n",
    "name  = [name.text.split(\"\\n\") for name in required_details]\n",
    "\n",
    "Company_Name = []\n",
    "number_of_salary = []\n",
    "Average_salary = []\n",
    "Min_salary = []\n",
    "Max_Salary = []\n",
    "\n",
    "for i in name:\n",
    "    Company_name.append(i[1])\n",
    "    number_of_salary.append(i[2])\n",
    "    Average_salary.append(i[4])\n",
    "    Min_salary.append(i[6])\n",
    "    Max_Salary.append(i[7])\n",
    "\n",
    "print(\"Company_name\",len(Company_name))\n",
    "print(\"number_of_salary\",len(number_of_salary))\n",
    "print(\"Average_salary\",len(Average_salary))\n",
    "print(\"Min_salary\",len(Min_salary))\n",
    "print(\"Max_Salary\",len(Max_Salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>number_of_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Min_salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>16 salaries</td>\n",
       "      <td>₹ 6,11,228</td>\n",
       "      <td>343</td>\n",
       "      <td>1,095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>577</td>\n",
       "      <td>2,213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 8,97,795</td>\n",
       "      <td>586</td>\n",
       "      <td>2,730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>355</td>\n",
       "      <td>1,613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>450</td>\n",
       "      <td>11,622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>1,069</td>\n",
       "      <td>1,520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>502</td>\n",
       "      <td>1,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>202</td>\n",
       "      <td>1,809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>575</td>\n",
       "      <td>1,520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>See 12 salaries from all locations</td>\n",
       "      <td>/yr</td>\n",
       "      <td>1,014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 12,07,110</td>\n",
       "      <td>620</td>\n",
       "      <td>1,695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company_name        number_of_salary  \\\n",
       "0   Tata Consultancy Services             16 salaries   \n",
       "1                   Accenture             14 salaries   \n",
       "2                         IBM             14 salaries   \n",
       "3          Ericsson-Worldwide             14 salaries   \n",
       "4                   Delhivery             14 salaries   \n",
       "5          UnitedHealth Group             11 salaries   \n",
       "6          Valiance Solutions              9 salaries   \n",
       "7               ZS Associates              8 salaries   \n",
       "8                 EXL Service              8 salaries   \n",
       "9              Data Scientist  Optum Global Solutions   \n",
       "10                 Innovaccer              8 salaries   \n",
       "\n",
       "                        Average_salary Min_salary Max_Salary  \n",
       "0                           ₹ 6,11,228        343      1,095  \n",
       "1                          ₹ 11,46,533        577      2,213  \n",
       "2                           ₹ 8,97,795        586      2,730  \n",
       "3                           ₹ 7,38,057        355      1,613  \n",
       "4                          ₹ 12,39,781        450     11,622  \n",
       "5                          ₹ 13,36,142      1,069      1,520  \n",
       "6                           ₹ 8,15,192        502      1,465  \n",
       "7                          ₹ 11,35,221        202      1,809  \n",
       "8                          ₹ 11,44,243        575      1,520  \n",
       "9   See 12 salaries from all locations        /yr      1,014  \n",
       "10                         ₹ 12,07,110        620      1,695  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Data frame\n",
    "glassdoor_df = pd.DataFrame({\"Company_name\":Company_name[:11],\"number_of_salary\":number_of_salary[:11],\"Average_salary\":Average_salary[:11],\"Min_salary\":Min_salary[:11],\"Max_Salary\":Max_Salary[:11]})\n",
    "glassdoor_df[\"Max_Salary\"] =  glassdoor_df[\"Max_Salary\"].map(lambda x: x.lstrip(\"₹\").rstrip(\"K\")) # reoving spacial char\n",
    "glassdoor_df[\"Min_salary\"] =  glassdoor_df[\"Min_salary\"].map(lambda x: x.lstrip(\"₹\").rstrip(\"K\")) # reoving spacial char\n",
    "glassdoor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you want to search :- Sunglasses\n",
      "brand_name_page 120\n",
      "Sunglass_title 160\n",
      "sunglass_price 160\n",
      "sunglass_discount 158\n"
     ]
    }
   ],
   "source": [
    "# calling chrome browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url =  \"https://www.flipkart.com/\" #url of the site\n",
    "driver.get(url) # opening URL\n",
    "driver.maximize_window()\n",
    "\n",
    "user_name = driver.find_element_by_xpath(\"//div [@class='IiD88i _351hSN']/input[@type ='text']\")\n",
    "user_name.send_keys(9727047686)\n",
    "\n",
    "\n",
    "password = driver.find_element_by_xpath(\"//div[@class='IiD88i _351hSN']/input[@type='password']\")\n",
    "password.send_keys(\"1234@1234\")\n",
    "\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='_1D1L_j']/button[@class='_2KpZ6l _2HKlqd _3AWRsL']\").click()\n",
    "\n",
    "\n",
    "# search sunglasses\n",
    "\n",
    "search = input(\"what do you want to search :- \")\n",
    "search_glasses = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[@type='text']\")\n",
    "search_glasses.clear()\n",
    "search_glasses.send_keys(search)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# submit button\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='col-12-12 _2oO9oE']/button[@class='L0Z3Pu']\").click() \n",
    "\n",
    "\n",
    "brand_name_page =[]\n",
    "Sunglass_title = []\n",
    "sunglass_price = []\n",
    "sunglass_discount = []\n",
    "for i in range(4):\n",
    "   \n",
    "    # sunglasses brand\n",
    "    try:\n",
    "        brand = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/div[1]')\n",
    "        for j in brand:\n",
    "            brand_name_page.append(j.text)\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        brand1 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "        for k in brand1:\n",
    "            brand_name_page.append(k.text)\n",
    "        time.sleep(5)\n",
    "        \n",
    "#     description of the sunglasess \n",
    "    try:\n",
    "        titles = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "        for title in titles:\n",
    "            Sunglass_title.append(title.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        titles1 = driver.find_elements_by_class_name('IRpwTa')\n",
    "        for title1 in titles1:\n",
    "            Sunglass_title.append(title1.text)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # price of the glass\n",
    "    try:\n",
    "        prices = driver.find_elements_by_xpath(\"//div[@class='_25b18c']/div[@class='_30jeq3']\")\n",
    "        for price in prices:\n",
    "            sunglass_price.append(price.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except:\n",
    "        prices1 = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div/div[@class='_30jeq3']\")\n",
    "        for price1 in prices1:\n",
    "            sunglass_price.append(price1.text)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # discoount applied\n",
    "    try:\n",
    "        discounts = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div/div[@class='_3Ay6Sb']\")\n",
    "        for discount in discounts:\n",
    "            sunglass_discount.append(discount.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except:\n",
    "        discounts1 = driver.find_elements_by_xpath(\"//div[@class='_25b18c']/div[@class='_3Ay6Sb']\")\n",
    "        for discount1 in discounts1:\n",
    "            sunglass_discount.append(discount1.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]/span\").click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"brand_name_page\",len(brand_name_page))\n",
    "print(\"Sunglass_title\",len(Sunglass_title))\n",
    "print(\"sunglass_price\",len(sunglass_price))\n",
    "print(\"sunglass_discount\",len(sunglass_discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name_page</th>\n",
       "      <th>Sunglass_title</th>\n",
       "      <th>sunglass_price</th>\n",
       "      <th>sunglass_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹570</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹215</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹259</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand_name_page                                     Sunglass_title  \\\n",
       "0            hipe   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "1         DEIXELS  UV Protection Retro Square Sunglasses (Free Size)   \n",
       "2          AISLIN              UV Protection Aviator Sunglasses (58)   \n",
       "3    Singco India       UV Protection Aviator Sunglasses (Free Size)   \n",
       "4    Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "\n",
       "  sunglass_price sunglass_discount  \n",
       "0           ₹570           28% off  \n",
       "1           ₹499           77% off  \n",
       "2           ₹215           72% off  \n",
       "3           ₹349           78% off  \n",
       "4           ₹259           82% off  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass_df = pd.DataFrame({\"brand_name_page\":brand_name_page[:100],\"Sunglass_title\":Sunglass_title[:100],\"sunglass_price\":sunglass_price[:100],\"sunglass_discount\":sunglass_discount[:100]})\n",
    "sunglass_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings 118\n",
      "Comment 120\n",
      "desc 120\n"
     ]
    }
   ],
   "source": [
    "# calling chrome browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url =  \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\" #url of the site\n",
    "driver.get(url) # opening URL\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "ratings = []\n",
    "comments = []\n",
    "desc = []\n",
    "for i in range(12):\n",
    "    \n",
    "    # rating which is given by the customer\n",
    "    try:\n",
    "        rating = driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div/div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for j in rating:\n",
    "            ratings.append(j.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        rating1 = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for k in rating1:\n",
    "            ratings.append(k.text)\n",
    "        time.sleep(3)\n",
    "    # comment given by customer \n",
    "    \n",
    "    try:\n",
    "        comment = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for l in comment:\n",
    "            comments.append(l.text)\n",
    "\n",
    "    except:\n",
    "        comment1 = driver.find_elements_by_xpath(\"//div[@class='row']/p[@class='_2-N8zT']\")\n",
    "        for m in comment1:\n",
    "            comments.append(m.text)\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # comment description\n",
    "    \n",
    "    try:\n",
    "        comm_desc = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for comm in comm_desc:\n",
    "            desc.append(comm.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        comm_desc = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "        for comm in comm_desc:\n",
    "            desc.append(comm.text)\n",
    "        time.sleep(3)\n",
    "    \n",
    "#     Clicking on next button\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]/span\").click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "        time.sleep(1)\n",
    "    \n",
    "        \n",
    "print(\"ratings\",len(ratings))\n",
    "print(\"Comment\",len(comments))\n",
    "print(\"desc\",len(desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>comments</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>It's a great phone. From camera to display eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>We are on apple ecosystem for almost eight yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings           comments  \\\n",
       "0        5          Brilliant   \n",
       "1        5   Perfect product!   \n",
       "2        5      Great product   \n",
       "3        5  Worth every penny   \n",
       "4        4        Good choice   \n",
       "..     ...                ...   \n",
       "95       3            Awesome   \n",
       "96       5     Decent product   \n",
       "97       5             Super!   \n",
       "98       5            Awesome   \n",
       "99       5     Classy product   \n",
       "\n",
       "                                                 desc  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  The phone is completely good\\nAs far as camera...  \n",
       "96  Everything u ll like it when u use this iPhone...  \n",
       "97  It's a great phone. From camera to display eve...  \n",
       "98  Can’t beat the software and hardware integrati...  \n",
       "99  We are on apple ecosystem for almost eight yea...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_df = pd.DataFrame({\"ratings\":ratings[:100],\"comments\":comments[:100],\"desc\":desc[:100]})\n",
    "iphone_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you want to search :- sneakers\n",
      "shoes_brand_name 120\n",
      "shoes_desc 133\n",
      "shoes_price 160\n",
      "shoes_discount 158\n"
     ]
    }
   ],
   "source": [
    "# calling chrome browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url =  \"https://www.flipkart.com/\" #url of the site\n",
    "driver.get(url) # opening URL\n",
    "driver.maximize_window()\n",
    "\n",
    "user_name = driver.find_element_by_xpath(\"//div [@class='IiD88i _351hSN']/input[@type ='text']\")\n",
    "user_name.send_keys(9727047686)\n",
    "\n",
    "\n",
    "password = driver.find_element_by_xpath(\"//div[@class='IiD88i _351hSN']/input[@type='password']\")\n",
    "password.send_keys(\"1234@1234\")\n",
    "\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='_1D1L_j']/button[@class='_2KpZ6l _2HKlqd _3AWRsL']\").click()\n",
    "\n",
    "\n",
    "# search sunglasses\n",
    "\n",
    "search = input(\"what do you want to search :- \")\n",
    "search_glasses = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[@type='text']\")\n",
    "search_glasses.clear()\n",
    "search_glasses.send_keys(search)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# submit button\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='col-12-12 _2oO9oE']/button[@class='L0Z3Pu']\").click() \n",
    "\n",
    "\n",
    "shoes_brand_name =[]\n",
    "shoes_desc = []\n",
    "shoes_price = []\n",
    "shoes_discount = []\n",
    "for i in range(4):\n",
    "   \n",
    "    # sunglasses brand\n",
    "    try:\n",
    "        brand = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/div[1]')\n",
    "        for j in brand:\n",
    "            shoes_brand_name.append(j.text)\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        brand1 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "        for k in brand1:\n",
    "            shoes_brand_name.append(k.text)\n",
    "        time.sleep(5)\n",
    "        \n",
    "#     description of the sunglasess \n",
    "    try:\n",
    "        description = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "        for title in description:\n",
    "            shoes_desc.append(title.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        description1 = driver.find_elements_by_class_name('IRpwTa')\n",
    "        for title1 in description1:\n",
    "            shoes_desc.append(title1.text)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # price of the glass\n",
    "    try:\n",
    "        prices = driver.find_elements_by_xpath(\"//div[@class='_25b18c']/div[@class='_30jeq3']\")\n",
    "        for price in prices:\n",
    "            shoes_price.append(price.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except:\n",
    "        prices1 = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div/div[@class='_30jeq3']\")\n",
    "        for price1 in prices1:\n",
    "            shoes_price.append(price1.text)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # discoount applied\n",
    "    try:\n",
    "        discounts = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div/div[@class='_3Ay6Sb']\")\n",
    "        for discount in discounts:\n",
    "            shoes_discount.append(discount.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except:\n",
    "        discounts1 = driver.find_elements_by_xpath(\"//div[@class='_25b18c']/div[@class='_3Ay6Sb']\")\n",
    "        for discount1 in discounts1:\n",
    "            shoes_discount.append(discount1.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]/span\").click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"shoes_brand_name\",len(shoes_brand_name))\n",
    "print(\"shoes_desc\",len(shoes_desc))\n",
    "print(\"shoes_price\",len(shoes_price))\n",
    "print(\"shoes_discount\",len(shoes_discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shoes_brand_name</th>\n",
       "      <th>shoes_desc</th>\n",
       "      <th>shoes_price</th>\n",
       "      <th>shoes_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹661</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹367</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axter</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zovim</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹377</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shoes_brand_name                                         shoes_desc  \\\n",
       "0       D-SNEAKERZ                                   Sneakers For Men   \n",
       "1            SPARX                                   Sneakers For Men   \n",
       "2            Axter     White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "3            zovim     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4           Kraasa  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "\n",
       "  shoes_price shoes_discount  \n",
       "0        ₹661        55% off  \n",
       "1        ₹367        63% off  \n",
       "2        ₹349        65% off  \n",
       "3        ₹379        62% off  \n",
       "4        ₹377        62% off  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_df =pd.DataFrame({\"shoes_brand_name\":shoes_brand_name[:100],\"shoes_desc\":shoes_desc[:100],\"shoes_price\":shoes_price[:100],\"shoes_discount\":shoes_discount[:100]})\n",
    "shoes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Go to the link - https://www.myntra.com/shoes<br>\n",
    "### Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image<br>\n",
    "### And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoes_brand 166\n",
      "shoes_desc 150\n",
      "only_shoes_price 150\n"
     ]
    }
   ],
   "source": [
    "# automating browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# clicking on price and color\n",
    "driver.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\").click()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "shoes_brand = []\n",
    "shoes_desc= []\n",
    "only_shoes_price =[]\n",
    "for i in range(1,4):\n",
    "     \n",
    "    # extracting shoes brand name\n",
    "    try:\n",
    "        brand = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "        for j in brand:\n",
    "            shoes_brand.append(j.text)\n",
    "        time.sleep(2)\n",
    "                        \n",
    "    except:\n",
    "        brand1 = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3[@class='product-brand']\")\n",
    "        for k in brand1:\n",
    "            shoes_brand.append(k.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# extracting description of the shoes that are below the brand\n",
    "    try:\n",
    "        desc = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "        for l in desc:\n",
    "            shoes_desc.append(i.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        desc1 = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4[@class='product-product']\")\n",
    "        for m in desc1:\n",
    "            shoes_desc.append(m.text)\n",
    "        time.sleep(2)\n",
    "        \n",
    "      #extracting shoes price \n",
    "    \n",
    "    try:\n",
    "        price  = driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "        shoes_price = [pri.text.split() for pri in price]\n",
    "        for n in shoes_price:\n",
    "            only_shoes_price.append(n[1])\n",
    "            \n",
    "    except:\n",
    "        price1  = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/div[@class='product-price']/span[1]\")\n",
    "        shoes_price1 = [pri.text.split() for pri in price1]\n",
    "        for o in shoes_price1:\n",
    "            only_shoes_price.append(o[1])\n",
    "    \n",
    "        \n",
    "    \n",
    "    time.sleep(3)    \n",
    "    driver.find_element_by_xpath(\"//li[@class='pagination-next']\").click()\n",
    "    \n",
    "print(\"shoes_brand\",len(shoes_brand))\n",
    "print(\"shoes_desc\",len(shoes_desc))\n",
    "print(\"only_shoes_price\",len(only_shoes_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Myntra_shoes = pd.DataFrame({\"shoes_brand\":shoes_brand[:100],\"only_shoes_price\":only_shoes_price[:100],\"shoes_desc\":shoes_desc[:100]})\n",
    "Myntra_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes \n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract i7 process laptop information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define your search:-  Laptops\n",
      "laptop_title 30\n",
      "laptop_rating 24\n",
      "laptop_price 26\n"
     ]
    }
   ],
   "source": [
    "# Automate browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.amazon.in/\"\n",
    "\n",
    "# opening site\n",
    "driver.get(url)\n",
    "\n",
    "# maximize the window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Search items\n",
    "\n",
    "user_input = input(\"define your search:-  \") # user input for searching item\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\") #automate the brower\n",
    "# search_bar.clear() #clear the brower if any thing written \n",
    "search_bar.send_keys(user_input) #send input to browser\n",
    "time.sleep(3)\n",
    "\n",
    "# click on search button\n",
    "submit = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "submit.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# logic for clicking on i9 product\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class ='a-size-base a-color-base']\"):\n",
    "    if i.text == \"Intel Core i7\":\n",
    "        i.click()\n",
    "        break\n",
    "    time.sleep(1)\n",
    "        \n",
    "# scrapping the title of laptop but before that we will take the url of each laptop for extracting the info\n",
    "\n",
    "# extracting URLs\n",
    "url = driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "urls =[]\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    \n",
    "# creating empty list    \n",
    "laptop_title = []\n",
    "laptop_price = []\n",
    "laptop_rating = []\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # extracting laptop description\n",
    "    desc = driver.find_elements_by_xpath(\"//h1[@class='a-size-large a-spacing-none']\")\n",
    "    for j in desc:\n",
    "        laptop_title.append(j.text) \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # extracting laptop rating\n",
    "    rating = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "    for k in rating:\n",
    "        laptop_rating.append(k.text)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # extracting laptop price\n",
    "    try:\n",
    "        price = driver.find_elements_by_xpath(\"//td[@class='a-span12']/span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        for l in price:\n",
    "            laptop_price.append(l.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        price1 = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        for m in price1:\n",
    "            laptop_price.append(m.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "print(\"laptop_title\",len(laptop_title))\n",
    "print(\"laptop_rating\",len(laptop_rating))\n",
    "print(\"laptop_price\",len(laptop_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract i9 process laptop information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define your search:-  Laptops\n",
      "laptop_title_i9 9\n",
      "laptop_rating_i9 7\n",
      "laptop_price_i9 8\n"
     ]
    }
   ],
   "source": [
    "# Automate browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.amazon.in/\"\n",
    "\n",
    "# opening site\n",
    "driver.get(url)\n",
    "\n",
    "# maximize the window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Search items\n",
    "\n",
    "user_input = input(\"define your search:-  \") # user input for searching item\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\") #automate the brower\n",
    "# search_bar.clear() #clear the brower if any thing written \n",
    "search_bar.send_keys(user_input) #send input to browser\n",
    "time.sleep(3)\n",
    "\n",
    "# click on search button\n",
    "submit = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "submit.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# logic for clicking on i9 product\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class ='a-size-base a-color-base']\"):\n",
    "    if i.text == \"Intel Core i9\":\n",
    "        i.click()\n",
    "        break\n",
    "    time.sleep(1)\n",
    "        \n",
    "# scrapping the title of laptop but before that we will take the url of each laptop for extracting the info\n",
    "\n",
    "# extracting URLs\n",
    "url = driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "urls =[]\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    \n",
    "# creating empty list    \n",
    "laptop_title_i9 = []\n",
    "laptop_price_i9 = []\n",
    "laptop_rating_i9 = []\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # extracting laptop description\n",
    "    desc = driver.find_elements_by_xpath(\"//h1[@class='a-size-large a-spacing-none']\")\n",
    "    for j in desc:\n",
    "        laptop_title_i9.append(j.text) \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # extracting laptop rating\n",
    "    rating = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "    for k in rating:\n",
    "        laptop_rating_i9.append(k.text)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # extracting laptop price\n",
    "    try:\n",
    "        price = driver.find_elements_by_xpath(\"//td[@class='a-span12']/span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        for l in price:\n",
    "            laptop_price_i9.append(l.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        price1 = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        for m in price1:\n",
    "            laptop_price_i9.append(m.text)\n",
    "        time.sleep(2)\n",
    "print(\"laptop_title_i9\",len(laptop_title_i9))\n",
    "print(\"laptop_rating_i9\",len(laptop_rating_i9))\n",
    "print(\"laptop_price_i9\",len(laptop_price_i9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laptop_title_i9</th>\n",
       "      <th>laptop_rating_i9</th>\n",
       "      <th>laptop_price_i9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "      <td>₹ 2,62,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹ 2,66,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple MacBook Pro (16-inch, 16GB RAM, 1TB Stor...</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "      <td>₹ 2,24,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>2.4 out of 5</td>\n",
       "      <td>₹ 2,99,325.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...</td>\n",
       "      <td>4.8 out of 5</td>\n",
       "      <td>₹ 2,51,526.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "      <td>₹ 2,77,490.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>₹ 2,00,690.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     laptop_title_i9 laptop_rating_i9  \\\n",
       "0  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...     3.7 out of 5   \n",
       "1  ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...     4.2 out of 5   \n",
       "2  Apple MacBook Pro (16-inch, 16GB RAM, 1TB Stor...     3.8 out of 5   \n",
       "3  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...     2.4 out of 5   \n",
       "4  Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...     4.8 out of 5   \n",
       "5  ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...     3.4 out of 5   \n",
       "6  (Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...       5 out of 5   \n",
       "\n",
       "  laptop_price_i9  \n",
       "0   ₹ 2,62,990.00  \n",
       "1   ₹ 2,66,990.00  \n",
       "2   ₹ 2,24,990.00  \n",
       "3   ₹ 2,99,325.00  \n",
       "4   ₹ 2,51,526.00  \n",
       "5   ₹ 2,77,490.00  \n",
       "6   ₹ 2,00,690.00  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i9_df  = pd.DataFrame({\"laptop_title_i9\":laptop_title_i9[:7],\"laptop_rating_i9\":laptop_rating_i9[:7],\"laptop_price_i9\":laptop_price_i9[:7]})\n",
    "i9_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
