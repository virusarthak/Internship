{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib\n",
    "import os\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Write a python program which searches all the product under a particular product verticalfrom www.amazon.in. The product verticals to be searched will be taken as input from user.For e.g. If user input is ‘guitar’. Then search for guitars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product name :- Air conditioner\n"
     ]
    }
   ],
   "source": [
    "# Automating the browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url = \"https://www.amazon.in/\"\n",
    "\n",
    "# opending brower\n",
    "\n",
    "driver.get(url) # we are opening the url which is saved in the url variable \n",
    "driver.maximize_window() # it will maximize the website page \n",
    "\n",
    "# user will provide input \n",
    "user_input = input(\"Enter the product name :- \") # by using this code, program will ask user to enter the product name\n",
    "\n",
    "# automate the search bar\n",
    "search_bar= driver.find_element_by_id(\"twotabsearchtextbox\") # it the search bar ID,which will help to automate the search bar\n",
    "search_bar.send_keys(user_input) # send_keys is the functon which take user_input to the website search bar\n",
    "time.sleep(2) # we want our program to be stopped for 2 sec\n",
    "\n",
    "# click on search\n",
    "\n",
    "driver.find_element_by_id(\"nav-search-submit-button\").click() # automating the the submit button, once user input goes to search bar, it will wait for 2 sec and then click on submit button  \n",
    "time.sleep(2) # after clicking the submit button program to be stopped for 2 sec\n",
    "\n",
    "\n",
    "# continue second question\n",
    "\n",
    "# this question will follow the second question in the same sequence, we will extract the url of a product and from the product will extract required information and details.\n",
    "\n",
    "product_url = [] # creating empty list and will save all the url in this list\n",
    "for i in range(3): # we are asked to scrap first 3 pages thus loop is run till 3 time\n",
    "    urls = driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\") # xpath for urls\n",
    "    time.sleep(2) # program will stop for 2 sec\n",
    "    for j in urls: # this loop will itterate over urls and extract url and append in product url list and program will rest for 2 sec\n",
    "        product_url.append(j.get_attribute(\"href\"))\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # written next button code to jump to next page, have written the same code in try block \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='a-text-center']/ul/li[7]/a\").click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//li[@class='a-last']/a\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a dataframe and csv. In case if any product vertical has less than 3 pages in search results then scrape all the products available under that product vertical. Details to be scraped are:\n",
    "\"Brand Name\",<br>\n",
    "\"Name of the Product\", <br>\n",
    "\"Rating\", <br>\n",
    "\"No. of Ratings\", <br>\n",
    "\"Price\", <br>\n",
    "\"Return/Exchange\", <br>\n",
    "\"Expected Delivery\", <br>\n",
    "\"Availability\", <br>\n",
    "\"Other Details\" <br>\n",
    "“Product URL”. <br>\n",
    "In case, if any of the details are missing for any of the product then replace it by “-“\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are continuing with second question from here, in this question we will extract the information from the urls which are extracted in question one\n",
    "# created number of emtpy list for saving the scrap information \n",
    "Brand_Name =[]\n",
    "Name_of_the_Product =[] \n",
    "Rating = [] \n",
    "No_of_Ratings =[] \n",
    "Price =[] \n",
    "Return_Exchange =[] \n",
    "Expected_Delivery =[] \n",
    "Availability =[]\n",
    "Other_Details =[]\n",
    "\n",
    "\"\"\" Below mentioned code is extracting the information from the urls, i have defined the product's spacification one by one \n",
    " and extracting information accordinly by defining the particular xpath, have written code in try and except block if item is not \n",
    "  found then that should be replace with hyphen \"\"\"\n",
    "\n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "#     Brand_name\n",
    "    try:\n",
    "        brand_name = driver.find_element_by_xpath(\"//div[@class='a-expander-content a-expander-section-content a-section-expander-inner']/table/tbody/tr[1]/td\")\n",
    "        Brand_Name.append(brand_name.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Brand_Name.append(\"-\")\n",
    "        \n",
    "#     Name_of_the_Product\n",
    "\n",
    "    try:\n",
    "        product_name = driver.find_element_by_id(\"productTitle\")\n",
    "        Name_of_the_Product.append(product_name.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Name_of_the_Product.append(\"-\")\n",
    "        \n",
    "    # Rating\n",
    "    \n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        Rating.append(rating.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Rating.append(\"-\")\n",
    "        \n",
    "    # No_of_Ratings\n",
    "    \n",
    "    try:\n",
    "        rating_count = driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-none a-spacing-top-mini cr-widget-ACR']/div[2]/span\")\n",
    "        No_of_Ratings.append(rating_count.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        No_of_Ratings.append(\"-\")\n",
    "        \n",
    "    #Price \n",
    "    \n",
    "    try:\n",
    "        price = driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        Price.append(price.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Price.append(\"-\")\n",
    "    \n",
    "    # Return_Exchange\n",
    "    try:\n",
    "        return_exchange = driver.find_element_by_xpath(\"//div[@id='RETURNS_POLICY']/span/div[2]/a\")\n",
    "        Return_Exchange.append(return_exchange.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Return_Exchange.append(\"-\")\n",
    "    \n",
    "   #Expected_Delivery\n",
    "\n",
    "    try:\n",
    "        delivery =driver.find_element_by_id(\"ddmDeliveryMessage\")\n",
    "        Expected_Delivery.append(delivery.text.strip())\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Expected_Delivery.append(\"-\")\n",
    "        \n",
    "    # Availability\n",
    "    \n",
    "    try:\n",
    "        prod_status = driver.find_element_by_xpath(\"//div[@id='availability_feature_div']/div/span\")\n",
    "        Availability.append(prod_status.text.strip())\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Availability.append(\"-\")\n",
    "        \n",
    "#     other_details\n",
    "    try:\n",
    "        other_detail = driver.find_element_by_xpath(\"//ul[@class='a-unordered-list a-vertical a-spacing-mini']\") \n",
    "        Other_Details.append(other_detail.text)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        Other_Details.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_Name))\n",
    "print(len(Name_of_the_Product))\n",
    "print(len(Price))\n",
    "print(len(Return_Exchange))\n",
    "print(len(Expected_Delivery))\n",
    "print(len(Availability))\n",
    "print(len(Other_Details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Write a python program to access the search bar and search button on images.google.com and scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you want me to search? :- fruits\n",
      "How many image you want? : 100\n"
     ]
    }
   ],
   "source": [
    "# In is questions, we are extracting images of fruits, Cars and Machine leaning and saving them into folder\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\") # chrome driver is required to automate the chrome browser\n",
    "\n",
    "url = \"https://images.google.com/\" \n",
    "\n",
    "# opending brower & maximixzing the \n",
    "\n",
    "driver.get(url) \n",
    "driver.maximize_window()\n",
    "\n",
    "# folder in which photos will be saved\n",
    "\n",
    "save_folder = \"Fruit image\" # folder name\n",
    "os.makedirs(save_folder)\n",
    "\n",
    "# automate search box\n",
    "\n",
    "user_search = input(\"what do you want me to search? :- \")  # code will ask for user to enter the item\n",
    "count_of_img  = int(input(\"How many image you want? : \")) # how many images user wants to scrap, will be entered as int \n",
    "search_box = driver.find_element_by_xpath(\"//input[@class ='gLFyf gsfi']\") # search box xpath for accessing the search bar\n",
    "search_box.send_keys(user_search) # send_keys will take user input to search bar\n",
    "time.sleep(1) # program will stop for 1 sec\n",
    "\n",
    "# automate search_button \n",
    "\n",
    "driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\").click() # automating the submit button, once input will be given to search bar, program will stop for 1 sec and then click \n",
    "time.sleep(1)\n",
    "\n",
    "# this below mentioned code will scroll the the page down  \n",
    "value = 0\n",
    "for i in range(5):\n",
    "    driver.execute_script(\"scrollBy(\"+str(value)+\",+1000);\")\n",
    "    value +=1000\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "image_url = driver.find_elements_by_xpath(\"//div[@class ='bRMDJf islir']/img\") # saving images url in the image_url variable\n",
    "\n",
    "\"\"\"Running for loop for extracting the images, we are taking index value and pics from the loop, \n",
    "given condition that images to be scrapped less than user given count\"\"\"\n",
    "url = []\n",
    "for index,i in enumerate(image_url):\n",
    "    if index < count_of_img:\n",
    "        url =(i.get_attribute(\"src\"))\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url,os.path.join(save_folder,user_search+str(index)+'.jpg'))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car image scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you want me to search? :- Cars\n",
      "How many image you want? : 100\n"
     ]
    }
   ],
   "source": [
    "# as we have scrapped the fruits images, similar way we are extracting the cars and machine learning images\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url = \"https://images.google.com/\"\n",
    "\n",
    "# opending brower\n",
    "\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# folder in which photos will be saved\n",
    "\n",
    "save_folder = \"Cars image\"\n",
    "os.mkdir(save_folder)\n",
    "\n",
    "# automate search box\n",
    "\n",
    "user_search = input(\"what do you want me to search? :- \")\n",
    "count_of_img  = int(input(\"How many image you want? : \"))\n",
    "search_box = driver.find_element_by_xpath(\"//input[@class ='gLFyf gsfi']\")\n",
    "search_box.send_keys(user_search)\n",
    "time.sleep(1)\n",
    "\n",
    "# automate search_button \n",
    "\n",
    "driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "value = 0\n",
    "for i in range(5):\n",
    "    driver.execute_script(\"scrollBy(\"+str(value)+\",+1000);\")\n",
    "    value +=1000\n",
    "    time.sleep(1)\n",
    "\n",
    "try:\n",
    "    image_url = driver.find_elements_by_xpath(\"//div[@class ='bRMDJf islir']/img\")\n",
    "except:\n",
    "    image_url = driver.find_elemetns_by_xpath(\"//img[@class='rg_i Q4LuWd']\")\n",
    "    \n",
    "\"\"\"Running for loop for extracting the images, we are taking index value and pics from the loop, \n",
    "given condition that images to be scrapped less than user given count\"\"\"\n",
    "\n",
    "for index,i in enumerate(image_url):\n",
    "    if index < count_of_img:\n",
    "        url =(i.get_attribute(\"src\"))\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url,os.path.join(save_folder,user_search+str(index)+'.jpg'))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you want me to search? :- Machine learning\n",
      "How many image you want? : 100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"as we have scrapped the fruits cars, similar way we are extracting the machine learning images\"\"\"\n",
    "# Automating the browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url = \"https://images.google.com/\"\n",
    "\n",
    "# opending brower\n",
    "\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# folder in which photos will be saved\n",
    "\n",
    "save_folder = \"Machine learning image\"\n",
    "os.mkdir(save_folder)\n",
    "\n",
    "# automate search box\n",
    "\n",
    "user_search = input(\"what do you want me to search? :- \")\n",
    "count_of_img  = int(input(\"How many image you want? : \"))\n",
    "search_box = driver.find_element_by_xpath(\"//input[@class ='gLFyf gsfi']\")\n",
    "search_box.send_keys(user_search)\n",
    "time.sleep(1)\n",
    "\n",
    "# automate search_button \n",
    "\n",
    "driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# scrolling down so that images can be downloaded \n",
    "value = 0\n",
    "for i in range(5):\n",
    "    driver.execute_script(\"scrollBy(\"+str(value)+\",+1000);\")\n",
    "    value +=1000\n",
    "    time.sleep(1)\n",
    "\n",
    "try:\n",
    "    image_url = driver.find_elements_by_xpath(\"//div[@class ='bRMDJf islir']/img\")\n",
    "except:\n",
    "    image_url = driver.find_elemetns_by_xpath(\"//img[@class='rg_i Q4LuWd']\")\n",
    "\n",
    "\"\"\"Running for loop for extracting the images, we are taking index value and pics from the loop, \n",
    "given condition that images to be scrapped less than user given count\"\"\"    \n",
    "    \n",
    "for index,i in enumerate(image_url):\n",
    "    if index < count_of_img:\n",
    "        url = i.get_attribute(\"src\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url,os.path.join(save_folder,user_search+str(index)+'.jpg'))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4:- Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. \n",
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, \n",
    "“Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display \n",
    "Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. \n",
    "Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe \n",
    "and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product name:- Redmi phones\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# we will search a product and extract all the information of that product from this program. we will also open complete \n",
    "spacification list so that we can download all required info\"\"\"\n",
    "\n",
    "# automating browser and opening website\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# when we open flipkart, it asks for login details and we have to skip that. so below xpath will cancel it\n",
    "try:\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click() \n",
    "except:\n",
    "    driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    \n",
    "\n",
    "# automating search bar, user will provide input, send_keys will take user input to the search bar and search it.\n",
    "user_search = input(\"Enter the product name:- \")\n",
    "search_bar = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "search_bar.send_keys(user_search)\n",
    "time.sleep(2)\n",
    "\n",
    "# Submit button , will search the item\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click() #clicking on submit button \n",
    "time.sleep(2)\n",
    "\n",
    "# extracting the urls of the product and with these urls we will get the required information\n",
    "url = driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\") # extracting URls\n",
    "Product_url = [i.get_attribute(\"href\") for i in url]\n",
    "\n",
    "\n",
    "# creating empty lists for saving the details\n",
    "\n",
    "Brand_name =[]\n",
    "Smartphone_name =[]\n",
    "color =[]\n",
    "RAM = []\n",
    "ROM =  []\n",
    "Primary_camera = []\n",
    "Secondary_cam = []\n",
    "Display_size = []\n",
    "Display_reso = []\n",
    "Processor = []\n",
    "Process_cores = []\n",
    "Battery_capa = []\n",
    "Price = []\n",
    "\n",
    "\"\"\" Running a loop for extracting all the information which are mentioned above as empty lists, xpath is being defined for \n",
    "extracting the desire details and if any product's details is missing , replace that one with 'NA' \"\"\"\n",
    "\n",
    "for i in Product_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # brand name\n",
    "    try:\n",
    "        brand = driver.find_element_by_xpath(\"//h1[@class ='yhB1nd']/span\")\n",
    "        Brand_name.append(brand.text.split()[0])\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Brand_name.append(\"NA\")\n",
    "    \n",
    "    # Price\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        Price.append(price.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Price.append(\"NA\")\n",
    "        \n",
    "#     we have a button names \"readfull\", while opening it specification will expand and we can see all details.\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _1FH0tX']\").click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # Smartphone_name\n",
    "    try:\n",
    "        phone_name = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[1]/table/tbody/tr[3]/td[2]/ul/li\")\n",
    "        Smartphone_name.append(phone_name.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Smartphone_name.append(\"NA\")\n",
    "    \n",
    "     # phone color   \n",
    "    try:\n",
    "        Color = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[1]/table/tbody/tr[4]/td[2]/ul/li\")\n",
    "        color.append(Color.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        color.append(\"NA\")\n",
    "    \n",
    "    # Ram status\n",
    "    try:\n",
    "        ram = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[4]/table/tbody/tr[2]/td[2]/ul/li\")\n",
    "        RAM.append(ram.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        RAM.append(\"NA\")\n",
    "    \n",
    "    #ROM Status\n",
    "    try:\n",
    "        rom = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[4]/table/tbody/tr[1]/td[2]/ul/li\")\n",
    "        ROM.append(ram.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        ROM.append(\"NA\")\n",
    "        \n",
    "    # Primany Camera\n",
    "    try:\n",
    "        p_cam = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[5]/table/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Primary_camera.append(p_cam.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Primary_camera.append(\"NA\")\n",
    "        \n",
    "    # secondary cam\n",
    "    try:\n",
    "        s_cam = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[5]/table/tbody/tr[5]/td[2]/ul/li\")\n",
    "        Secondary_cam.append(s_cam.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Secondary_cam.append(\"NA\")\n",
    "\n",
    "    #  Display_size  \n",
    "    try:\n",
    "        display_size = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[2]/table/tbody/tr[1]/td[2]/ul/li\")\n",
    "        Display_size.append(display_size.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Display_size.append(\"NA\")\n",
    "        \n",
    "    # Display_reso\n",
    "    try:\n",
    "        display_reso = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[2]/table/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Display_reso.append(display_reso.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Display_reso.append(\"NA\")\n",
    "    \n",
    "    # Processor\n",
    "    try:\n",
    "        Proc = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[3]/table/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Processor.append(Proc.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Processor.append(\"NA\")\n",
    "        \n",
    "    # Process_cores\n",
    "    \n",
    "    try:\n",
    "        proc_cores = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[3]/table/tbody/tr[3]/td[2]/ul/li\")\n",
    "        Process_cores.append(proc_cores.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Process_cores.append(\"NA\")\n",
    "        \n",
    "    # Battery_capa\n",
    "    try:\n",
    "        battery = driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[10]/table/tbody/tr[1]/td[2]/ul/li\")\n",
    "        Battery_capa.append(battery.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        Battery_capa.append(\"NA\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Smartphone_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Smartphone_name</th>\n",
       "      <th>color</th>\n",
       "      <th>RAM</th>\n",
       "      <th>ROM</th>\n",
       "      <th>Primary_camera</th>\n",
       "      <th>Secondary_cam</th>\n",
       "      <th>Display_size</th>\n",
       "      <th>Display_reso</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Process_cores</th>\n",
       "      <th>Battery_capa</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi</td>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>Sporty Orange</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>13MP + 8MP</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>720 x 1600$$pixel</td>\n",
       "      <td>MediaTek Helio G35</td>\n",
       "      <td>2.3 GHz</td>\n",
       "      <td>5000 mAh</td>\n",
       "      <td>₹9,184</td>\n",
       "      <td>https://www.flipkart.com/redmi-9-sporty-orange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi</td>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>Sky Blue</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>13MP + 2MP</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>720 x 1600$$pixel</td>\n",
       "      <td>MediaTek Helio G35</td>\n",
       "      <td>2.3 GHz</td>\n",
       "      <td>5000 mAh</td>\n",
       "      <td>₹9,199</td>\n",
       "      <td>https://www.flipkart.com/redmi-9-sky-blue-64-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmi</td>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>Carbon Black</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>13MP + 2MP</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>720 x 1600$$pixel</td>\n",
       "      <td>MediaTek Helio G35</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>5000 mAh</td>\n",
       "      <td>₹9,438</td>\n",
       "      <td>https://www.flipkart.com/redmi-9-carbon-black-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi</td>\n",
       "      <td>Redmi 9A</td>\n",
       "      <td>Midnight Black</td>\n",
       "      <td>2 GB</td>\n",
       "      <td>2 GB</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>720 x 1600$$pixel</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>2 MHz</td>\n",
       "      <td>1 Year Manufacturer Warranty</td>\n",
       "      <td>₹7,349</td>\n",
       "      <td>https://www.flipkart.com/redmi-9a-midnight-bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi</td>\n",
       "      <td>Redmi 9A</td>\n",
       "      <td>Nature Green</td>\n",
       "      <td>2 GB</td>\n",
       "      <td>2 GB</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>720 x 1600$$pixel</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>2 GHz</td>\n",
       "      <td>1 Year Manufacturer Warranty</td>\n",
       "      <td>₹7,360</td>\n",
       "      <td>https://www.flipkart.com/redmi-9a-nature-green...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand_name Smartphone_name           color   RAM   ROM    Primary_camera  \\\n",
       "0      Redmi         Redmi 9   Sporty Orange  4 GB  4 GB        13MP + 8MP   \n",
       "1      Redmi         Redmi 9        Sky Blue  4 GB  4 GB        13MP + 2MP   \n",
       "2      Redmi         Redmi 9    Carbon Black  4 GB  4 GB        13MP + 2MP   \n",
       "3      Redmi        Redmi 9A  Midnight Black  2 GB  2 GB  13MP Rear Camera   \n",
       "4      Redmi        Redmi 9A    Nature Green  2 GB  2 GB  13MP Rear Camera   \n",
       "\n",
       "      Secondary_cam          Display_size       Display_reso  \\\n",
       "0  5MP Front Camera  16.59 cm (6.53 inch)  720 x 1600$$pixel   \n",
       "1  5MP Front Camera  16.59 cm (6.53 inch)  720 x 1600$$pixel   \n",
       "2  5MP Front Camera  16.59 cm (6.53 inch)  720 x 1600$$pixel   \n",
       "3               Yes  16.59 cm (6.53 inch)  720 x 1600$$pixel   \n",
       "4               Yes  16.59 cm (6.53 inch)  720 x 1600$$pixel   \n",
       "\n",
       "            Processor Process_cores                  Battery_capa   Price  \\\n",
       "0  MediaTek Helio G35       2.3 GHz                      5000 mAh  ₹9,184   \n",
       "1  MediaTek Helio G35       2.3 GHz                      5000 mAh  ₹9,199   \n",
       "2  MediaTek Helio G35     Octa Core                      5000 mAh  ₹9,438   \n",
       "3           Octa Core         2 MHz  1 Year Manufacturer Warranty  ₹7,349   \n",
       "4           Octa Core         2 GHz  1 Year Manufacturer Warranty  ₹7,360   \n",
       "\n",
       "                                         Product_url  \n",
       "0  https://www.flipkart.com/redmi-9-sporty-orange...  \n",
       "1  https://www.flipkart.com/redmi-9-sky-blue-64-g...  \n",
       "2  https://www.flipkart.com/redmi-9-carbon-black-...  \n",
       "3  https://www.flipkart.com/redmi-9a-midnight-bla...  \n",
       "4  https://www.flipkart.com/redmi-9a-nature-green...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redmi_phones_df = pd.DataFrame({\"Brand_name\":Brand_name,\"Smartphone_name\":Smartphone_name,\"color\":color,\"RAM\":RAM,\"ROM\":ROM,\n",
    "                               \"Primary_camera\":Primary_camera,\"Secondary_cam\":Secondary_cam,\"Display_size\":Display_size,\"Display_reso\":Display_reso,\n",
    "                               \"Processor\":Processor,\"Process_cores\":Process_cores,\"Battery_capa\":Battery_capa,\"Price\":Price,\"Product_url\":Product_url})\n",
    "redmi_phones_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city name:- delhi\n",
      "https://www.google.com/maps/place/Delhi/@28.6472799,76.8130609,10z/data=!3m1!4b1!4m5!3m4!1s0x390cfd5b347eb62d:0x37205b715389640!8m2!3d28.7040592!4d77.1024902\n",
      "**********************************************************************\n",
      "Location coordinates\n",
      "delhi Latitude 28.6472799\n",
      "delhi Longitude 76.8130609\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This program will extract the latitude and longitude information of the place, we will automate the browser first and then \n",
    "open the google map and then write the location name, once we enter location name , we will have latitude an longitude information \n",
    "available in the current page url, so we will extract the url and and then extract the required information by using the regex\"\"\"\n",
    "\n",
    "# automate the browser and opening site \n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.google.com/maps\"\n",
    "driver.get(url)\n",
    "driver.maximize_window() # site page will be maximize\n",
    "\n",
    "# write in search box\n",
    "\n",
    "user_input = input(\"Enter the city name:- \") # user input, code will ask for input from user\n",
    "search_bar = driver.find_element_by_id(\"searchboxinput\") # xpath for search box\n",
    "search_bar.send_keys(user_input) # sending user input to searchbar \n",
    "time.sleep(2)\n",
    "\n",
    "# submit_button\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='searchbox-searchbutton-container']/button\").click() # click on search button to search item\n",
    "time.sleep(2)\n",
    "\n",
    "# fecting current URL from the webpage to extract the desire output  \n",
    "current_page_url = driver.current_url # \n",
    "print(current_page_url) # printing the url\n",
    "\n",
    "# extracting the lat and log from the url by using the reges, \\d+.\\d+ it will match all the number and extract it\n",
    "location_coordinates = re.findall('(\\d+.\\d+)',current_page_url) # it will result a comma seprated list and by sliceing we can extract the required information  \n",
    "\n",
    "# printing the lat and log \n",
    "print(\"*\"*70) # printing star just to seprate url and end result\n",
    "print(\"Location coordinates\")\n",
    "print(user_input,\"Latitude\",location_coordinates[0]) # at 0th index , we have attitude and at 1st index we have longitude\n",
    "print(user_input,\"Longitude\",location_coordinates[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************** September 2020****************************** \n",
      "\n",
      "Sr. No. Date (dd/mm/yyyy) Startup Name Industry / Vertical Sub-Vertical City / Location Investors' Name Investment Type Amount (In USD) \n",
      "\n",
      "1 08/09/2020 Byju’s EduTech Online Tutoring Bangalore Silver Lake, Tiger Global, General Atlantic and Owl Ventures Private Equity 500,000,000 \n",
      "2 12/09/2020 mCaffeine Personal Care Skincare & Haircare Mumbai Amicus Capital Private Equity I LLP, Amicus Capital Partners India Fund I and RP-SG Venture Fund 1 Series B 3,000,000 \n",
      "3 09/09/2020 Qshala EduTech Online Curiosity Platform for Kids Bangalore Rainmatter Capital Angel 370,000 \n",
      "4 02/09/2020 Winzo Online Gaming Online Gaming New Delhi Kalaari Capital Partners, IndigoEdge Management Consultancy Series B 15,500,000 \n",
      "5 09/09/2020 Hippo Video Video Customer Experience(CX) Platform Video Customer Experience(CX) Platform Newark, Delaware, United States of Amercia Alpha Wave Incubation, Exfinity Venture Partners and existing backers. Series A 4,500,000 \n",
      "6 07/09/2020 Melorra E-commerce Online Jewelry Store Bangalore Shadow Holdings, Lightbox. Debt Financing upto 8,900,000 \n",
      "7 07/09/2020 1mg E-commerce Online Pharmacy Gurgaon Gaja Capital, Tata Capital, Partners Group In Progress 100,000,000 \n",
      "8 31/08/2020 mfine HealthTech On-Demand Healthcare Services Bangalore Caretech Pte Inc Series B 5,400,000 \n",
      "9 31/08/2020 Apna Human Resources Recruitment Platform Bangalore Lightspeed India and Sequoia Capital India Series A 8,000,000 \n",
      "10 03/09/2020 Railofy Transportation WL & RAC protection platform Mumbai Chiratae Ventures Seed 950,000 \n",
      "11 08/09/2020 Cell Propulsion Automobile Electric Mobility Solutions Bangalore growX Ventures and Micelio pre-Series A NA \n",
      "\n",
      "**************************** August 2020****************************** \n",
      "\n",
      "Sr. No. Date (dd/mm/yyyy) Startup Name Industry / Vertical Sub-Vertical City / Location Investors' Name Investment Type Amount (In USD) \n",
      "\n",
      "1 15/08/2020 Practo HealthTech Health care and Wellness Bangalore A1A Company Series F 32,000,000 \n",
      "2 13/08/2020 Medlife E-commerce Online Pharmacy Bangalore Prasid Uno Family Trust and SC Credit Fund  23,000,000 \n",
      "3 13/08/2020 HungerBox FoodTech Online Food Delivery Service Bangalore One97, Sabre Partners Trust, Pratithi Investment Trust, and Srihari Kumar Series D1 1,560,000 \n",
      "4 04/08/2020 Dunzo Hyper-local Logistics Online Delivery Services Bangalore Existing Backers In Progress 30,000,000 \n",
      "5 11/08/2020 Terra.do EduTech Online Climate School, E-learning Stanford, California, Stanford Angels and Entrepreneurs (India), BEENEXT Emerging Asia, Rainmatter Capital Seed 1,400,000 \n",
      "6 12/08/2020 Classplus EduTech E-learning, Online Tutoring Noida Falcon Edge In Progress upto 15,000,000 \n",
      "7 14/08/2020 Niyo FinTech Financial Services Bangalore Niyo Solutions Inc.  6,000,000 \n",
      "8 10/08/2020 ZestMoney FinTech Financial Services Bangalore Primrose Hills Ventures  10,670,000 \n",
      "9 07/08/2020 FreshToHome E-commerce Food Delivery Bangalore Ascent Capital Venture 16,200,000 \n",
      "10 13/08/2020 Eduvanz FinTech Financial Services Mumbai Sequoia India, Unitus Series A 5,000,000 \n",
      "11 03/08/2020 CrowdPouch FinTech Financial Services Bangalore Elina Investments Pvt. Ltd Angel NA \n",
      "12 04/08/2020 DrinkPrime Water Purification Water Purification Bangalore Sequoia Surge, ON Mauritius Pre-Series A 2,880,000 \n",
      "\n",
      "**************************** July 2020****************************** \n",
      "\n",
      "Sr. No. Date (dd/mm/yyyy) Startup Name Industry / Vertical Sub-Vertical City / Location Investors' Name Investment Type Amount (In USD) \n",
      "\n",
      "1 15/07/2020 Flipkart E-commerce E-commerce Bangalore Walmart Inc M&A 1,200,000,000 \n",
      "2 16/07/2020 Vedantu EduTech Online Tutoring Bangalore Coatue Management Series D 100,000,000 \n",
      "3 16/07/2020 Crio EduTech Learning Platform for Developers Bangalore 021 Capital pre-Series A 934,160 \n",
      "4 14/07/2020 goDutch FinTech Group Payments Mumbai Matrix India,Y Combinator, Global Founders Capital, Soma Capital, and VentureSouq. Seed 1,700,000 \n",
      "5 13/07/2020 Mystifly Airfare Marketplace Ticketing, Airline Retailing, and Post-Ticketing Services Singapore and Bangalore Recruit Co. Ltd. pre-Series B 3,300,000 \n",
      "6 09/07/2020 JetSynthesys Gaming and Entertainment Gaming and Entertainment Pune Adar Poonawalla and Kris Gopalakrishnan. Venture-Series Unknown 400,000 \n",
      "7 10/07/2020 gigIndia Marketplace Crowd Sourcing, Freelance Pune Incubate Fund India and Beyond Next Ventures pre-Series A 974,200 \n",
      "8 15/07/2020 PumPumPum Automotive Rental Used Car-leasing platform Gurgaon Early Adapters Syndicate Seed 292,800 \n",
      "9 14/07/2020 FLYX OTT Player Streaming Social Network New York and Delhi Raj Mishra, founder of AIT Global Inc pre-Seed 200,000 \n",
      "10 13/07/2020 Open Appliances Pvt. Ltd. Information Technology Internet-of-Things Security Solutions Bangalore Unicorn India Ventures Venture-Series Unknown 500,000 \n"
     ]
    }
   ],
   "source": [
    "# automate browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://trak.in/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# opening funding details tab\n",
    "\n",
    "funding_details = driver.find_element_by_xpath(\"//li[@id='menu-item-51510']/a\").get_attribute(\"href\")\n",
    "driver.get(funding_details)\n",
    "time.sleep(2)\n",
    "\n",
    "# each table contain maximum 10 rows on the front page, we need to select all the rows from drop down, so that i am using select command for the same \n",
    "drop_down = Select(driver.find_element_by_xpath(\"//div[@id='tablepress-50_length']/label/select\"))\n",
    "time.sleep(2)\n",
    "drop_down.select_by_value(\"100\") # i am selecting the drop down from value, we can select it from index or visible text options also\n",
    "\n",
    "# it will be used for printing the header \n",
    "cols = driver.find_elements_by_xpath(\"//*[@id='tablepress-51_wrapper']/div[3]/div[1]/div/table/thead/tr/th\") \n",
    "\n",
    "# we are taking the lenght of row and col, so that we can run loop until rows and cols and we can fetch the data accordingly \n",
    "rows = len(driver.find_elements_by_xpath(\"//*[@id='tablepress-50']/tbody/tr\"))\n",
    "col = len(driver.find_elements_by_xpath(\"//*[@id='tablepress-51_wrapper']/div[3]/div[1]/div/table/thead/tr/th\"))\n",
    "\n",
    "print(\"**************************** September 2020****************************** \\n\")\n",
    "\n",
    "for i in cols:\n",
    "    print(i.text,end =\" \")\n",
    "    \n",
    "print(\"\\n\") # giving a line \n",
    "\"\"\"i have created two loops one for rows and second for columns,it will run untill last row. have defined xpath in the xpath\n",
    "i have passed row and cols as paraeter and extracting the information one by one\"\"\"\n",
    "\n",
    "for r in range(1,rows+1):\n",
    "    for c in range(1,col+1):\n",
    "        # as menioned passing rows and col in the xpath converting number into string\n",
    "        value = driver.find_element_by_xpath(\"//*[@id='tablepress-50']/tbody/tr[\"+str(r)+\"]/td[\"+str(c)+\"]\").text\n",
    "        print(value, end = \" \") # printing all the value line by line\n",
    "    print() # this prinint is helping to print the next line from\n",
    "\n",
    "\n",
    "######################## August\n",
    "\n",
    "# each table contain maximum 10 rows on the front page, we need to select all the rows from drop down, so that i am using select command for the same \n",
    "drop_down = Select(driver.find_element_by_xpath(\"//div[@id='tablepress-49_length']/label/select\"))\n",
    "time.sleep(2)\n",
    "drop_down.select_by_value(\"100\") # i am selecting the drop down from value, we can select it from index or visible text options also\n",
    "\n",
    "# it will be used for printing the header \n",
    "cols = driver.find_elements_by_xpath(\"//*[@id='tablepress-49_wrapper']/div[3]/div[1]/div/table/thead/tr/th\") \n",
    "\n",
    "# we are taking the lenght of row and col, so that we can run loop until rows and cols and we can fetch the data accordingly \n",
    "rows = len(driver.find_elements_by_xpath(\"//*[@id='tablepress-49']/tbody/tr\"))\n",
    "col = len(driver.find_elements_by_xpath(\"//*[@id='tablepress-49_wrapper']/div[3]/div[1]/div/table/thead/tr/th\"))\n",
    "\n",
    "print(\"\\n**************************** August 2020****************************** \\n\")\n",
    "\n",
    "for i in cols:\n",
    "    print(i.text,end =\" \")\n",
    "    \n",
    "print(\"\\n\") # giving a line \n",
    "\"\"\"i have created two loops one for rows and second for columns,it will run untill last row. have defined xpath in the xpath\n",
    "i have passed row and cols as paraeter and extracting the information one by one\"\"\"\n",
    "\n",
    "for r in range(1,rows+1):\n",
    "    for c in range(1,col+1):\n",
    "        # as menioned passing rows and col in the xpath converting number into string\n",
    "        value = driver.find_element_by_xpath(\"//*[@id='tablepress-49']/tbody/tr[\"+str(r)+\"]/td[\"+str(c)+\"]\").text\n",
    "        print(value, end = \" \") # printing all the value line by line\n",
    "    print() # this prinint is helping to print the next line from\n",
    "\n",
    "\n",
    "############################### July\n",
    "\n",
    "# each table contain maximum 10 rows on the front page, we need to select all the rows from drop down, so that i am using select command for the same \n",
    "drop_down = Select(driver.find_element_by_xpath(\"//div[@id='tablepress-48_length']/label/select\"))\n",
    "time.sleep(2)\n",
    "drop_down.select_by_value(\"100\") # i am selecting the drop down from value, we can select it from index or visible text options also\n",
    "\n",
    "# it will be used for printing the header \n",
    "cols = driver.find_elements_by_xpath(\"//*[@id='tablepress-48_wrapper']/div[3]/div[1]/div/table/thead/tr/th\") \n",
    "\n",
    "# we are taking the lenght of row and col, so that we can run loop until rows and cols and we can fetch the data accordingly \n",
    "rows = len(driver.find_elements_by_xpath(\"//*[@id='tablepress-48']/tbody/tr\"))\n",
    "col = len(driver.find_elements_by_xpath(\"//*[@id='tablepress-48_wrapper']/div[3]/div[1]/div/table/thead/tr/th\"))\n",
    "\n",
    "\n",
    "print(\"\\n**************************** July 2020****************************** \\n\")\n",
    "\n",
    "for i in cols:\n",
    "    print(i.text,end =\" \")\n",
    "    \n",
    "print(\"\\n\") # giving a line \n",
    "\"\"\"i have created two loops one for rows and second for columns,it will run untill last row. have defined xpath in the xpath\n",
    "i have passed row and cols as paraeter and extracting the information one by one\"\"\"\n",
    "\n",
    "for r in range(1,rows+1):\n",
    "    for c in range(1,col+1):\n",
    "        # as menioned passing rows and col in the xpath converting number into string\n",
    "        value = driver.find_element_by_xpath(\"//*[@id='tablepress-48']/tbody/tr[\"+str(r)+\"]/td[\"+str(c)+\"]\").text\n",
    "        print(value, end = \" \") # printing all the value line by line\n",
    "    print() # this prinint is helping to print the next line from\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7:- Write a program to scrap all the available details of top 10 gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter the search:- Gaming Laptop\n"
     ]
    }
   ],
   "source": [
    "# We are going to scrap details of gaming laptops from digit.in\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "driver.get(\"https://www.digit.in/\") # opening website \n",
    "driver.maximize_window() # maximizing the page of the site\n",
    "\n",
    "# open search\n",
    "\n",
    "# here search bar is not as we have seen on other sites, we will have to open the search bar here and then write, so i am doing the same here\n",
    "driver.find_element_by_xpath(\"//div[@class='search']/a\").click() # clicking on search bar to open it\n",
    "\n",
    "\n",
    "user_search = input(\"please enter the search:- \")  # once search bar is open, user will type input there and that will happen by automating it, i am doing the same in next line of code\n",
    "search_bar = driver.find_element_by_id(\"globalPageSearchText\") # it has been automate by using xpath \n",
    "search_bar.send_keys(user_search) # i am sending the user input to search bar with send_keys help\n",
    "time.sleep(2) # and stopping program for 2 sec\n",
    "search_bar.send_keys(Keys.ENTER) # there is no submit or click button on the search bar, thus i am using keys.enter to press the enter so that it can search the item\n",
    "time.sleep(3) # and give time to open the page after search by stopping the program for 3 sec\n",
    "\n",
    "\n",
    "\"\"\" from here i am going to extract details of the product, it will be comprising product name, os , display, processor \n",
    " memory and price, i will define xpath of each aspect and get the details if we dont get any details it should replace 'NA' \n",
    " \n",
    " each code below is written in such a manner that first it will extract the information and then stop the program for 2 sec \n",
    " then jump next information. here we are extracting the same\n",
    " \n",
    " \"\"\"\n",
    "\n",
    "\n",
    "# here we are extracting product name and url of the product\n",
    "\n",
    "# product_name\n",
    "product = driver.find_elements_by_xpath(\"//div[@class='searchProduct-desc']\")\n",
    "product_name = [i.text for i in product]\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# extracting url:\n",
    "url = driver.find_elements_by_xpath(\"//div[@class='searchPage']/a\")\n",
    "urls = [link.get_attribute(\"href\") for link in url]\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# creating empty list for saving the result of the product information\n",
    "OS= []\n",
    "Display = []\n",
    "Processor = []\n",
    "memory = []\n",
    "Price = []\n",
    "\n",
    "# running loops, it will take product url and open it one by one and then extract the details accordingly  \n",
    "for i in urls: \n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # laptop specificaion:\n",
    "#     extracing OS\n",
    "    try:\n",
    "        Os = driver.find_element_by_xpath(\"//div[@class='key-specifications']/div/ul/li[1]/div[1]\")\n",
    "        OS.append(Os.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        OS.append(\"NA\")\n",
    "    \n",
    "    # extracing Display related information\n",
    "        \n",
    "    try:\n",
    "        display = driver.find_element_by_xpath(\"//div[@class='key-specifications']/div/ul/li[2]/div[1]\")\n",
    "        Display.append(display.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "         Display.append(\"NA\")\n",
    "\n",
    "            \n",
    "    # extracing Processor related information\n",
    "    \n",
    "    try:\n",
    "        processor = driver.find_element_by_xpath(\"//div[@class='key-specifications']/div/ul/li[3]/div[1]\")\n",
    "        Processor.append(processor.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "         Processor.append(\"NA\")\n",
    "        \n",
    "    # extracing Memory related information\n",
    "    \n",
    "    try:\n",
    "        Memo = driver.find_element_by_xpath(\"//div[@class='key-specifications']/div/ul/li[4]/div[1]\")\n",
    "        memory.append(Memo.text)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "         memory.append(\"NA\")\n",
    "            \n",
    "#     extracing price related information\n",
    "    try:\n",
    "        rate = driver.find_element_by_xpath(\"//div[@class='Block-price']/b/i\")\n",
    "        Price.append(rate.text)\n",
    "    except:\n",
    "        Price.append(\"NA\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(OS))\n",
    "print(len(Display))\n",
    "print(len(Processor))\n",
    "print(len(memory))\n",
    "print(len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
